{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOrMbDawxOIQkMCwA8Qxx0q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","from torchvision import transforms\n","from torchvision import datasets\n","import torch.nn as nn\n","import ssl\n","from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n","from matplotlib import pyplot as plt\n","import math\n","import time\n","import os\n","import torch.nn.functional as F\n","\n","ssl._create_default_https_context = ssl._create_unverified_context\n","\n","EPOCH = 10\n","epochs = EPOCH\n","pre_epoch = 0\n","\n","def PLOTIMAGE(acc,val_acc,loss,val_loss):\n","    # 绘制精度曲线\n","    plt.plot(epochs, acc)\n","    plt.plot(epochs, val_acc)\n","    plt.title('Training and validation accuracy')\n","    plt.legend(('Training accuracy', 'validation accuracy'))\n","    plt.figure()\n","    # 绘制损失曲线\n","    plt.plot(epochs, loss)\n","    plt.plot(epochs, val_loss)\n","    plt.legend(('Training loss', 'validation loss'))\n","    plt.title('Training and validation loss')\n","    plt.show()\n","    return 1\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n","model.fc = nn.Linear(in_features=2048, out_features=2, bias=True)\n","base_dir = './cat_and_dog'\n","#指定每一种数据的位置\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'val')\n","BATCH_SIZE = 16\n","LR = 0.0001\n","net = model.to(device)\n","# define loss funtion & optimizer\n","criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9,weight_decay=0.1)\n","optimizer = optim.Adam(net.parameters(), lr=LR)\n","\n","preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","traindata_dirname = train_dir\n","train_data = datasets.ImageFolder(traindata_dirname, preprocess)\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n","\n","testdata_dirname = validation_dir\n","test_data = datasets.ImageFolder(testdata_dirname, preprocess)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE * 2, shuffle=False)\n","if __name__ == \"__main__\":\n","    Test_acc = 0\n","    Test_AUC = 0\n","    Test_Sen = 0\n","    Test_Spe = 0\n","    Test_npv = 0\n","    Test_ppv = 0\n","    for epoch in range(pre_epoch, EPOCH):\n","        since = time.time()\n","        print('\\nEpoch: %d' % (epoch + 1))\n","        net.train()\n","        sum_loss = 0.0\n","        correct = 0.0\n","        total = 0.0\n","        train_acc = 0\n","        label_train = []\n","        prob_train = []\n","        for i, data in enumerate(trainloader, 0):\n","            length = len(trainloader)\n","            # print(\"length\",length)\n","            inputs, label = data\n","            inputs, label = inputs.to(device), label.to(device)\n","            optimizer.zero_grad()\n","            # forward & backward\n","            outputs = net(inputs)\n","\n","            # print(\"outputs:\",outputs)\n","            print(\"Before softmax shape: \", outputs.shape)\n","            probabilities = torch.nn.functional.softmax(outputs, dim=0)\n","            print(\"After softmax shape: \", probabilities.shape)\n","            loss = criterion(probabilities, label)\n","            loss.backward()\n","            optimizer.step()\n","            # print ac & loss in each batch\n","            sum_loss += loss.item()\n","            # print(\"probabilities:\",probabilities)\n","            _, predicted = torch.max(probabilities, 1)\n","            prob_train.extend(predicted.cpu().data.numpy())\n","            label_train.extend(label.cpu().numpy())\n","            # print(\"predicted\",predicted)\n","            # print(\"label\",label)\n","            total += label.size(0)\n","            correct += (predicted == label).sum()\n","            # print(\"size\",label.size(0))\n","            # print(\"correct\",correct)\n","            # print(\"total\",total)\n","            train_acc = correct / total\n","            print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n","                  % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * train_acc))\n","        TN, FP, FN, TP = confusion_matrix(label_train, prob_train).ravel()\n","        Sen = float(TP) / (TP + FN)\n","        Spe = float(TN) / (FP + TN)\n","        npv = float(TN) / (TN + FN)\n","        ppv = float(TP) / (TP + FP)\n","        time_elapsed = time.time() - since\n","        print('Train\\'s ac is: %.3f%%' % (100 * train_acc))\n","        print('Training complete in {}s'.format(time_elapsed))\n","        print('Waiting Test...')\n","        prob_test = []\n","        label_test = []\n","        with torch.no_grad():\n","            correct_test = 0\n","            total_test = 0\n","            since = time.time()\n","            for data in testloader:\n","                net.eval()\n","                images, labels_test = data\n","                images, labels_test = images.to(device), labels_test.to(device)\n","                outputs_test = net(images)\n","                probabilities_test = torch.nn.functional.softmax(outputs_test, dim=1)\n","                loss = criterion(probabilities_test, labels_test)\n","                sum_test = probabilities_test[:, 0] + probabilities_test[:, 1]\n","                _, predicted_test = torch.max(probabilities_test, 1)  # 每行最大值\n","                prob_test.extend(predicted_test.data.cpu().numpy())\n","                label_test.extend(labels_test.data.cpu().numpy())\n","                total_test += labels_test.size(0)\n","                correct_test += (predicted_test == labels_test).sum()\n","            test_acc = correct_test / total_test\n","            time_elapsed = time.time() - since\n","            print('Test\\'s ac is: %.3f%%' % (100 * test_acc))\n","            print('Testing complete in {}s'.format(time_elapsed))\n","            # print(label_all,prob_all)\n","            TN_tt, FP_tt, FN_tt, TP_tt = confusion_matrix(label_test, prob_test).ravel()\n","            Sen_tt = float(TP_tt) / (TP_tt + FN_tt)\n","            Spe_tt = float(TN_tt) / (FP_tt + TN_tt)\n","            npv_tt = float(TN_tt) / (TN_tt + FN_tt)\n","            ppv_tt = float(TP_tt) / (TP_tt + FP_tt)\n","            num = 0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"jh_yapj2Oc5m","executionInfo":{"status":"error","timestamp":1678780856342,"user_tz":-480,"elapsed":102234,"user":{"displayName":"汤济玮","userId":"17722932606773371846"}},"outputId":"3c11a3d4-775a-41dc-ad33-19ce49fb9d12"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch: 1\n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:1] Loss: 0.691 | Acc: 56.250% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:2] Loss: 0.678 | Acc: 78.125% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:3] Loss: 0.671 | Acc: 85.417% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:4] Loss: 0.664 | Acc: 89.062% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:5] Loss: 0.659 | Acc: 91.250% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:6] Loss: 0.655 | Acc: 92.708% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:7] Loss: 0.652 | Acc: 93.750% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:8] Loss: 0.650 | Acc: 94.531% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:9] Loss: 0.648 | Acc: 95.139% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:10] Loss: 0.646 | Acc: 95.625% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:11] Loss: 0.645 | Acc: 96.023% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:12] Loss: 0.644 | Acc: 96.354% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:13] Loss: 0.643 | Acc: 96.635% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:14] Loss: 0.643 | Acc: 96.875% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:15] Loss: 0.642 | Acc: 97.083% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:16] Loss: 0.642 | Acc: 97.266% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:17] Loss: 0.641 | Acc: 97.426% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:18] Loss: 0.641 | Acc: 97.222% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:19] Loss: 0.641 | Acc: 97.368% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:20] Loss: 0.640 | Acc: 97.500% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:21] Loss: 0.640 | Acc: 97.619% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:22] Loss: 0.640 | Acc: 97.727% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:23] Loss: 0.640 | Acc: 97.554% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:24] Loss: 0.639 | Acc: 97.656% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:25] Loss: 0.639 | Acc: 97.750% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:26] Loss: 0.639 | Acc: 97.837% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:27] Loss: 0.639 | Acc: 97.917% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:28] Loss: 0.638 | Acc: 97.991% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:29] Loss: 0.638 | Acc: 98.060% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:1, iter:30] Loss: 0.638 | Acc: 98.125% \n","Train's ac is: 98.125%\n","Training complete in 14.437134742736816s\n","Waiting Test...\n","Test's ac is: 100.000%\n","Testing complete in 1.6510050296783447s\n","\n","Epoch: 2\n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:31] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:32] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:33] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:34] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:35] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:36] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:37] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:38] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:39] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:40] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:41] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:42] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:43] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:44] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:45] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:46] Loss: 0.634 | Acc: 99.219% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:47] Loss: 0.634 | Acc: 99.265% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:48] Loss: 0.634 | Acc: 99.306% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:49] Loss: 0.634 | Acc: 99.342% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:50] Loss: 0.634 | Acc: 99.375% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:51] Loss: 0.634 | Acc: 99.405% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:52] Loss: 0.634 | Acc: 99.432% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:53] Loss: 0.633 | Acc: 99.457% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:54] Loss: 0.634 | Acc: 99.219% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:55] Loss: 0.634 | Acc: 99.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:56] Loss: 0.634 | Acc: 99.038% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:57] Loss: 0.634 | Acc: 99.074% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:58] Loss: 0.633 | Acc: 99.107% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:59] Loss: 0.633 | Acc: 99.138% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:2, iter:60] Loss: 0.633 | Acc: 99.167% \n","Train's ac is: 99.167%\n","Training complete in 12.981145143508911s\n","Waiting Test...\n","Test's ac is: 99.167%\n","Testing complete in 1.7918825149536133s\n","\n","Epoch: 3\n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:61] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:62] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:63] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:64] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:65] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:66] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:67] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:68] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:69] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:70] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:71] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:72] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:73] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:74] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:75] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:76] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:77] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:78] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:79] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:80] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:81] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:82] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:83] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:84] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:85] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:86] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:87] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:88] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:89] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:3, iter:90] Loss: 0.633 | Acc: 100.000% \n","Train's ac is: 100.000%\n","Training complete in 12.851308584213257s\n","Waiting Test...\n","Test's ac is: 100.000%\n","Testing complete in 2.0506503582000732s\n","\n","Epoch: 4\n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:91] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:92] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:93] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:94] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:95] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:96] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:97] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:98] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:99] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:100] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:101] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:102] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:103] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:104] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:105] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:106] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:107] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:108] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:109] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:110] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:111] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:112] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:113] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:114] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:115] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:116] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:117] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:118] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:119] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:4, iter:120] Loss: 0.633 | Acc: 100.000% \n","Train's ac is: 100.000%\n","Training complete in 13.500202894210815s\n","Waiting Test...\n","Test's ac is: 100.000%\n","Testing complete in 2.015122413635254s\n","\n","Epoch: 5\n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:121] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:122] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:123] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:124] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:125] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:126] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:127] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:128] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:129] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:130] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:131] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:132] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:133] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:134] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:135] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:136] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:137] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:138] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:139] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:140] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:141] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:142] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:143] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:144] Loss: 0.633 | Acc: 99.740% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:145] Loss: 0.633 | Acc: 99.750% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:146] Loss: 0.633 | Acc: 99.760% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:147] Loss: 0.633 | Acc: 99.769% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:148] Loss: 0.633 | Acc: 99.777% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:149] Loss: 0.633 | Acc: 99.784% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:5, iter:150] Loss: 0.633 | Acc: 99.792% \n","Train's ac is: 99.792%\n","Training complete in 12.749895572662354s\n","Waiting Test...\n","Test's ac is: 100.000%\n","Testing complete in 1.808650016784668s\n","\n","Epoch: 6\n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:151] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:152] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:153] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:154] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:155] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:156] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:157] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:158] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:159] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:160] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:161] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:162] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:163] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:164] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:165] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:166] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:167] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:168] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:169] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:170] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:171] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:172] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:173] Loss: 0.633 | Acc: 99.457% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:174] Loss: 0.633 | Acc: 99.479% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:175] Loss: 0.633 | Acc: 99.500% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:176] Loss: 0.633 | Acc: 99.519% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:177] Loss: 0.633 | Acc: 99.537% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:178] Loss: 0.633 | Acc: 99.554% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:179] Loss: 0.633 | Acc: 99.569% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:6, iter:180] Loss: 0.633 | Acc: 99.167% \n","Train's ac is: 99.167%\n","Training complete in 12.943180561065674s\n","Waiting Test...\n","Test's ac is: 94.167%\n","Testing complete in 1.5851187705993652s\n","\n","Epoch: 7\n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:181] Loss: 0.634 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:182] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:183] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:184] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:185] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:186] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:187] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:188] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:189] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:190] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:191] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:192] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:193] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:194] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:195] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:196] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:197] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:198] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:199] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:200] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:201] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:202] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:203] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n","[epoch:7, iter:204] Loss: 0.633 | Acc: 100.000% \n","Before softmax shape:  torch.Size([16, 2])\n","After softmax shape:  torch.Size([16, 2])\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-621212482a82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;31m# print ac & loss in each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","import os\n","path = '/content/drive/MyDrive/'\n","os.chdir(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0jRVmfWGk99","executionInfo":{"status":"ok","timestamp":1678780495178,"user_tz":-480,"elapsed":24729,"user":{"displayName":"汤济玮","userId":"17722932606773371846"}},"outputId":"3b8f7ea4-dee0-4334-a294-2fd42bf0dc77"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}]}