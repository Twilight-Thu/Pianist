{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "# 基于 PyTorch 构建卷积神经网络 CNN\n",
    "\n",
    "<br>\n",
    "\n",
    "## 0. 概述\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　在前面两项实验内容中，我们已经学习了 PyTorch 的基本数据类型 tensor 及其相关操作，并练习了如何通过 PyTorch 读入并处理数据集。下面，我们就正式开始学习如何基于 PyTorch 搭建一个神经网络，并在 MNIST 数据集上进行训练和测试。\n",
    "    \n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　总体来讲，我们在这部分实验中要进行的操作包括以下几点：\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　1) 　读取和处理数据集\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　2) 　定义一个包含可训练参数的神经网络\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　3) 　从数据集中取出一个批次 (batch) 的样本传递给神经网络\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　4) 　通过神经网络处理输入样本\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　5) 　计算损失 (loss)\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　6) 　反向传播计算偏导\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　7) 　更新网络的参数 (一个简单的更新方法：weight = weight - learning_rate *gradient)\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　8) 　重复 3) 到 7) 步，不断调整网络参数\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入 PyTorch 及其他相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>查看 PyTorch 版本，是否可以使用 GPU，及 CUDA 的版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n",
      "True\n",
      "10.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准备数据集 (Data Preparation)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100  # 设置训练集和测试集的 batch size，即每批次将参与运算的样本数\n",
    "\n",
    "train_set = torchvision.datasets.MNIST('./dataset_mnist', train=True, download=True,\n",
    "                                       transform=torchvision.transforms.Compose([\n",
    "                                           torchvision.transforms.ToTensor(),\n",
    "                                           torchvision.transforms.Normalize(\n",
    "                                               (0.1307,), (0.3081,)\n",
    "                                           )\n",
    "                                       ])\n",
    ")\n",
    "\n",
    "##################### please finish the code ########################\n",
    "\n",
    "# 请把之前在“1_mnist_dataset_import.ipynb”中写的 test_set 代码复制在这里\n",
    "# test_set = XXX\n",
    "test_set = torchvision.datasets.MNIST('./dataset_mnist', train=False, download=True,\n",
    "                                      transform=torchvision.transforms.Compose([\n",
    "                                          torchvision.transforms.ToTensor(),\n",
    "                                          torchvision.transforms.Normalize(\n",
    "                                              (0.1307,), (0.3081,)\n",
    "                                          )\n",
    "                                      ])\n",
    "                                      )\n",
    "\n",
    "################################ end ################################\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3.  定义一个神经网络\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　为了构建神经网络，我们将使用 torch.nn 包，它是 PyTorch 的神经网络库。我们通常会将 torch.nn 包直接导入并命名为 nn。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font color=black size=3 face=雅黑>　　PyTorch 的神经网络库包含了构建神经网络所需的所有典型组件。我们构建一个神经网络使用的最主要组件是层，所以 PyTorch 的神经网络库包含了帮助我们构造层的类。在神经网络包里有一类被称为“模块” (nn.Module) 的特殊类，它是所有神经网络模块的母类。PyTorch 中所有的神经网络层均继承了 nn.Module。    \n",
    "\n",
    "<br>    \n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　神经网络中的每一层都包含两个主要组成部分，第一是该层参数的集合 (weights and biases)，第二是该层进行的变换 (transformation)。其中，进行的变换主要指前向传播过程，每一个 PyTorch nn.Module 都有一个 forward() 函数来定义其前向传播。因此，当我们实现一个自定义的神经网络 (nn.Module 子类) 时，也需要编写其 forward() 函数。值得注意的是，得益于 PyTorch 的自动求导功能，我们并不需要像“实验一”中一样自己编写反向传播的 backward() 函数，PyTorch 会自动帮我们完成。（关于这一点，我们会在之后的实验中详细为大家介绍。）\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　总结起来，在 PyTorch 中定义神经网络包括如下几个步骤：\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　　1) 基于 nn.Module 创建一个类 (extend the nn.Module base class)　\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　　2) 在类构造函数中，将网络的层定义为类属性 (define layers as class attributes)\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　　3) 定义网络的前向传输 (implement the forward() method)\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　下面，我们就可以创建一个类来表示一个简单的神经网络。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.layer = None\n",
    "    \n",
    "    def forward(self, t):\n",
    "        t = self.layer(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　在这个例子中，我们扩展了 nn.Module 基类。它在构造函数中有一个虚拟层 (self.layer)，并在 forward() 函数中实现了一个虚拟的前向传播过程。forward() 接收来自神经网络输入端的张量 t，对其进行张量变换 (transformation)，并将变换后的结果返回。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　现在，让我们用一些真正的层来替代这个虚拟层，这些层将由PyTorch 神经网络库提供。我们将建立一个卷积神经网络，包含两个卷积层和三个全连接层。其中，卷积层我们将用 torch.nn 的内建层类 nn.Conv2d 来实现，全连接层将用 nn.Linear 来实现。\n",
    "\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　nn.Conv2d 可见 PyTorch 官网：   https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　nn.Linear 可见 PyTorch 官网：\n",
    "https://pytorch.org/docs/master/generated/torch.nn.Linear.html#torch.nn.Linear\n",
    "    \n",
    "<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　假设我们将使用 MNIST 数据集，每张图片为一个 28\\*28 的灰度图。在即将定义的神经网络中，每个卷积层之后我们都会进行池化操作 (pooling)，池化的 kernel 大小和 stride 均取 2（即每次将对 2*2 的元素进行 max pooling）。 池化层由于不包含可训练的参数，因此不作为 Network1 的类属性（class attribute），而是会在之后写入 forward() 函数里。\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　**请大家阅读以下代码，在实验报告中：**\n",
    "    \n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　  **1) 画出对应的网络结构（包含各层权重的形状）；**\n",
    "    \n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　  **2) 注明当一张图片输入进网络后各层输入、输出值的形状；（由于不考虑批量化处理图片，因此卷积层激活值以三维张量表示，全连接层激活值以一维张量表示即可。）**\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　  **3) 补全 “self.fc1”的代码。（[提示]：需要计算 fc1 层的输入激活向量的长度。）**\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network1(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Network1, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(in_channels=1,  # 输入通道数\n",
    "                               out_channels=6,  # 输出通道数\n",
    "                               kernel_size=5)  # kernel 大小 （对应四维权重张量的 dim2/dim3）\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        ##################### please finish the code ########################\n",
    "        \n",
    "        # self.fc1 = nn.Linear(in_features=XXX,  # 输入激活向量的长度\n",
    "        #                     out_features=120)  # 输出激活向量的长度    \n",
    "        self.fc1 = nn.Linear(in_features=192,  # 输入激活向量的长度\n",
    "                             out_features=120)  # 输出激活向量的长度\n",
    "        ################################ end ################################\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "        \n",
    "    def forward(self, t):\n",
    "        # we will implement the forward path later\n",
    "        t = self.pool1(F.relu(self.conv1(t)))\n",
    "        t = self.pool2(F.relu(self.conv2(t)))\n",
    "        t = self.fc1(t)\n",
    "        t = self.fc2(t)\n",
    "        t = self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　查看定义好的网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network1(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = Network1()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　查看卷积层及其参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1)\n",
    "print(network.conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.1374, -0.1571,  0.1716, -0.1089, -0.0602],\n",
      "          [ 0.1650, -0.0900, -0.1596,  0.0584, -0.1780],\n",
      "          [ 0.1025,  0.0006, -0.0053,  0.1643,  0.0172],\n",
      "          [-0.0898,  0.1827, -0.0343, -0.0658,  0.1190],\n",
      "          [-0.0979, -0.0075,  0.1803, -0.1945, -0.0229]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0404,  0.0069, -0.1702,  0.1188, -0.0949],\n",
      "          [ 0.0229,  0.0759, -0.1565,  0.0287,  0.0472],\n",
      "          [ 0.0144, -0.1261, -0.1770, -0.1682,  0.1396],\n",
      "          [ 0.1011, -0.0097,  0.0503, -0.0841,  0.1170],\n",
      "          [-0.1369,  0.0372, -0.1275, -0.1588, -0.1501]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1558, -0.1111, -0.0622,  0.1836, -0.0074],\n",
      "          [ 0.0988, -0.0321, -0.1011,  0.0416,  0.0888],\n",
      "          [-0.0324,  0.1643,  0.0623,  0.1197, -0.1037],\n",
      "          [-0.1130,  0.0424, -0.1538,  0.1787,  0.0648],\n",
      "          [ 0.1192, -0.0831,  0.0249,  0.1153,  0.0868]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1547, -0.0096,  0.0841, -0.1166,  0.1698],\n",
      "          [-0.1528,  0.0019, -0.1681, -0.0795,  0.0812],\n",
      "          [-0.1063,  0.0228,  0.0057,  0.0450,  0.1542],\n",
      "          [ 0.1960,  0.0202, -0.1701,  0.0043,  0.1868],\n",
      "          [-0.0219, -0.1856,  0.0180, -0.0046,  0.1888]]],\n",
      "\n",
      "\n",
      "        [[[-0.1442,  0.1683,  0.1559, -0.1623,  0.1981],\n",
      "          [-0.1597,  0.0039, -0.1393, -0.1083,  0.0032],\n",
      "          [ 0.1308,  0.0818, -0.1250,  0.0504,  0.1879],\n",
      "          [ 0.1985,  0.0350, -0.1546,  0.1798, -0.1907],\n",
      "          [ 0.0744, -0.1462, -0.0245,  0.0472, -0.0594]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0180,  0.1128,  0.0380,  0.0245, -0.0538],\n",
      "          [ 0.1802, -0.1548, -0.0106,  0.0713, -0.0720],\n",
      "          [-0.1375, -0.1978,  0.0481,  0.0427, -0.0949],\n",
      "          [ 0.1616,  0.1894,  0.1382,  0.0425,  0.0084],\n",
      "          [-0.0598, -0.1234, -0.1836, -0.0497, -0.0676]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1.weight)  # check the weights of conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "tensor([[[-0.1374, -0.1571,  0.1716, -0.1089, -0.0602],\n",
      "         [ 0.1650, -0.0900, -0.1596,  0.0584, -0.1780],\n",
      "         [ 0.1025,  0.0006, -0.0053,  0.1643,  0.0172],\n",
      "         [-0.0898,  0.1827, -0.0343, -0.0658,  0.1190],\n",
      "         [-0.0979, -0.0075,  0.1803, -0.1945, -0.0229]]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1.weight.shape)  # check the shape of conv1's weight tensor\n",
    "print(network.conv1.weight[0])  # check weigth[0]\n",
    "print(network.conv1.weight[0].shape)  # check the shape of weight[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　查看全连接层及其参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 192])\n",
      "torch.Size([192])\n"
     ]
    }
   ],
   "source": [
    "# weight tensor for fc layers\n",
    "print(network.fc1.weight.shape)\n",
    "print(network.fc1.weight[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　查看整个网络的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "fc1.weight \t\t torch.Size([120, 192])\n",
      "fc1.bias \t\t torch.Size([120])\n",
      "fc2.weight \t\t torch.Size([60, 120])\n",
      "fc2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n",
      "\n",
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "fc1.weight \t\t torch.Size([120, 192])\n",
      "fc1.bias \t\t torch.Size([120])\n",
      "fc2.weight \t\t torch.Size([60, 120])\n",
      "fc2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 方式一\n",
    "for name, param in network.named_parameters():\n",
    "    print(name, '\\t\\t', param.shape)\n",
    "print(\"\")    \n",
    "\n",
    "#方式二\n",
    "for name in network.state_dict():  # state dictionary\n",
    "    print(name, '\\t\\t', network.state_dict()[name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "tensor([[[[-0.1374, -0.1571,  0.1716, -0.1089, -0.0602],\n",
      "          [ 0.1650, -0.0900, -0.1596,  0.0584, -0.1780],\n",
      "          [ 0.1025,  0.0006, -0.0053,  0.1643,  0.0172],\n",
      "          [-0.0898,  0.1827, -0.0343, -0.0658,  0.1190],\n",
      "          [-0.0979, -0.0075,  0.1803, -0.1945, -0.0229]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0404,  0.0069, -0.1702,  0.1188, -0.0949],\n",
      "          [ 0.0229,  0.0759, -0.1565,  0.0287,  0.0472],\n",
      "          [ 0.0144, -0.1261, -0.1770, -0.1682,  0.1396],\n",
      "          [ 0.1011, -0.0097,  0.0503, -0.0841,  0.1170],\n",
      "          [-0.1369,  0.0372, -0.1275, -0.1588, -0.1501]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1558, -0.1111, -0.0622,  0.1836, -0.0074],\n",
      "          [ 0.0988, -0.0321, -0.1011,  0.0416,  0.0888],\n",
      "          [-0.0324,  0.1643,  0.0623,  0.1197, -0.1037],\n",
      "          [-0.1130,  0.0424, -0.1538,  0.1787,  0.0648],\n",
      "          [ 0.1192, -0.0831,  0.0249,  0.1153,  0.0868]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1547, -0.0096,  0.0841, -0.1166,  0.1698],\n",
      "          [-0.1528,  0.0019, -0.1681, -0.0795,  0.0812],\n",
      "          [-0.1063,  0.0228,  0.0057,  0.0450,  0.1542],\n",
      "          [ 0.1960,  0.0202, -0.1701,  0.0043,  0.1868],\n",
      "          [-0.0219, -0.1856,  0.0180, -0.0046,  0.1888]]],\n",
      "\n",
      "\n",
      "        [[[-0.1442,  0.1683,  0.1559, -0.1623,  0.1981],\n",
      "          [-0.1597,  0.0039, -0.1393, -0.1083,  0.0032],\n",
      "          [ 0.1308,  0.0818, -0.1250,  0.0504,  0.1879],\n",
      "          [ 0.1985,  0.0350, -0.1546,  0.1798, -0.1907],\n",
      "          [ 0.0744, -0.1462, -0.0245,  0.0472, -0.0594]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0180,  0.1128,  0.0380,  0.0245, -0.0538],\n",
      "          [ 0.1802, -0.1548, -0.0106,  0.0713, -0.0720],\n",
      "          [-0.1375, -0.1978,  0.0481,  0.0427, -0.0949],\n",
      "          [ 0.1616,  0.1894,  0.1382,  0.0425,  0.0084],\n",
      "          [-0.0598, -0.1234, -0.1836, -0.0497, -0.0676]]]])\n"
     ]
    }
   ],
   "source": [
    "# 查看 conv1 的参数\n",
    "print(network.state_dict()[\"conv1.weight\"].shape)\n",
    "print(network.state_dict()[\"conv1.weight\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　网络的卷积层和全连接层定义好了。现在，让我们来实现 forward() 函数。\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　神经网络 forward() 函数的编写通常需要使用来自 nn.functional 的函数，这个包为我们提供了许多实现前向传播时需要的神经网络操作，例如激活函数 ReLU 和池化操作 Max Pooling。值得注意的是，虽然我们常称它们为“激活层”和“池化层”，但实际上它们都是在执行某种操作，并不包含可训练的参数。因此，它们在 PyTorch 中并没有被作为层来处理，也没有继承 nn.Module 基类，而是包含在 nn.functional 中。\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　**请在实验报告中展示补全后的 Network2.forward()，并说明这样写的原因。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        ##################### please finish the code ########################\n",
    "        \n",
    "        # 请把之前 Network1 的 self.fc1 复制到这里：\n",
    "        # self.fc1 = nn.Linear(in_features=XXX, out_features=120)\n",
    "        self.fc1 = nn.Linear(in_features=192,  # 输入激活向量的长度\n",
    "                             out_features=120)  # 输出激活向量的长度   \n",
    "        ################################ end ################################\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "        \n",
    "    def forward(self, t):\n",
    "        \n",
    "        # conv1\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)  # 这里我们用到了 nn.functional 包中的激活函数 relu\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)  # 这里我们用到了 nn.functional 包中的池化函数 max_pool2d （max pooling）\n",
    "        \n",
    "        # conv2\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # 特别注意：最后一个卷积层的输出在流入全连接层之前，要对激活值的维度进行变换，变换后的张量\n",
    "        # 是二维张量，其中 dim0 对应该批次中的不同样本，dim1 对应每个样本流向全连接层的输入激活向量。\n",
    "        # 请完成如下代码。\n",
    "        \n",
    "        ##################### please finish the code ########################\n",
    "\n",
    "        # dim0：一个批次的样本数\n",
    "        # dim1：每一个样本的输入激活向量长度\n",
    "        \n",
    "        # t = t.reshape(XXX,XXX)\n",
    "        t = t.reshape((t.shape[0], -1))\n",
    "        ################################ end ################################\n",
    "\n",
    "        # fc1\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # fc2\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # output layer\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "    \n",
    "        self.fc1 = nn.Linear(in_features=192,  # 输入激活向量的长度  # 由模型网络计算得出的 192\n",
    "                             out_features=120)  # 输出激活向量的长度   \n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "        \n",
    "    def forward(self, t):\n",
    "        # conv1\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)  # 这里我们用到了 nn.functional 包中的激活函数 relu\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)  # 这里我们用到了 nn.functional 包中的池化函数 max_pool2d （max pooling）\n",
    "\n",
    "        # conv2\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = t.reshape((t.shape[0], -1))  # 此处将函数打平。dim0 对应该批次中的不同样本，dim1 对应每个样本流向全连接层的输入激活向量。\n",
    "        # fc1\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        # fc2\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        # output layer\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　在 PyTorch 中，当我们直接调用对象名称 conv1/conv2/fc1/fc2 并将输入 t 传递给它时，对应的 forward() 函数将被调用。因此，在上述代码中， 我们直接将输入 t 传递给了 conv1，而没有使用 t = self.conv1.forward(t)。\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　到这里，我们已经完成了神经网络的构建。下一步，我们将训练这个神经网络来处理手写字体识别任务。\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　在开始训练之前，我们先来看一下这个神经网络的正向传播过程。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f8dab95ec88>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 关掉 PyTorch 的自动求导功能\n",
    "torch.set_grad_enabled(False)\n",
    "# torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "network = Network2()\n",
    "\n",
    "# 我们取一批图片给 network\n",
    "batch = next(iter(train_loader))  # DataLoader object: train_loader\n",
    "images, labels = batch\n",
    "print(images.shape)  # rank-4 tensor\n",
    "print(labels.shape)\n",
    "\n",
    "output = network(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看 output 形状: rank-2 tensor （[batch_size, # of classes]）\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: \n",
      " tensor([0.1084, 0.1078, 0.1088, 0.1085, 0.1088, 0.1095, 0.1084, 0.1076, 0.1094,\n",
      "        0.1076, 0.1070, 0.1107, 0.1080, 0.1087, 0.1077, 0.1092, 0.1087, 0.1095,\n",
      "        0.1072, 0.1066, 0.1083, 0.1072, 0.1072, 0.1074, 0.1081, 0.1087, 0.1069,\n",
      "        0.1088, 0.1071, 0.1122, 0.1062, 0.1099, 0.1079, 0.1072, 0.1085, 0.1081,\n",
      "        0.1078, 0.1102, 0.1080, 0.1076, 0.1089, 0.1089, 0.1081, 0.1102, 0.1086,\n",
      "        0.1085, 0.1087, 0.1089, 0.1077, 0.1102, 0.1093, 0.1079, 0.1087, 0.1075,\n",
      "        0.1113, 0.1072, 0.1085, 0.1066, 0.1074, 0.1085, 0.1088, 0.1116, 0.1086,\n",
      "        0.1087, 0.1093, 0.1089, 0.1078, 0.1086, 0.1110, 0.1100, 0.1089, 0.1056,\n",
      "        0.1087, 0.1076, 0.1090, 0.1071, 0.1073, 0.1082, 0.1088, 0.1095, 0.1091,\n",
      "        0.1082, 0.1096, 0.1085, 0.1064, 0.1094, 0.1094, 0.1081, 0.1092, 0.1102,\n",
      "        0.1075, 0.1082, 0.1101, 0.1058, 0.1094, 0.1073, 0.1099, 0.1115, 0.1104,\n",
      "        0.1092], grad_fn=<MaxBackward0>)\n",
      "predicted labels: \n",
      " tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 3, 0, 1, 1, 1,\n",
      "        1, 0, 0, 3, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 3, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# F.softmax(t, dim=1）会为每个预测类返回一个概率值，这些概率值之和等于1。我们没有将这一步放在 Network2.forward()\n",
    "# 中来做，是因为我们在训练网络将使用交叉熵损失函数 nn.CrossEntropyLoss，它会在其输入上隐式的执行一个 Softmax 操作。\n",
    "output_prob = F.softmax(output, dim=1)\n",
    "\n",
    "# 在之前的练习中我们已经知道，torch.max(t, dim=1) 函数会返回两个 tensor，第一个 tensor 是每行的最大值；第二个\n",
    "# tensor是每行最大值的索引，反映了批处理中每个图像的预测标签。\n",
    "scores, predict_class = torch.max(output_prob, dim=1)\n",
    "\n",
    "print(\"scores: \\n\", scores)\n",
    "print(\"predicted labels: \\n\", predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual labels: \n",
      " tensor([8, 1, 8, 4, 1, 6, 9, 2, 2, 3, 7, 0, 8, 1, 2, 6, 6, 5, 6, 7, 1, 9, 4, 8,\n",
      "        2, 7, 2, 9, 2, 2, 7, 1, 4, 2, 0, 4, 2, 5, 2, 2, 9, 5, 4, 1, 9, 4, 1, 4,\n",
      "        2, 6, 9, 3, 8, 9, 6, 4, 1, 7, 0, 6, 6, 0, 6, 1, 0, 2, 3, 1, 6, 0, 1, 9,\n",
      "        1, 1, 5, 9, 4, 9, 4, 7, 2, 3, 5, 8, 5, 0, 6, 9, 1, 8, 7, 6, 2, 3, 9, 2,\n",
      "        3, 5, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "# 查看实际标签\n",
    "print(\"actual labels: \\n\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions:  8\n",
      "\"accuracy\":  8.0 %\n"
     ]
    }
   ],
   "source": [
    "# 计算这一批样本识别的“准确率”\n",
    "correct_predictions = (predict_class == labels).sum().item()  # 识别正确的次数\n",
    "print(\"correct predictions: \", correct_predictions)\n",
    "print(\"\\\"accuracy\\\": \", correct_predictions/len(labels)*100, \"%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　**把这一部分代码（从\"network = Network2()\"开始）多跑几次你会发现，每次 \"scores\"、\"predict_class\" 等都会发生变化，请思考这是为什么？另外，尽管\"scores\"每一次都不同，但其大致取值却都差不多，这又是为什么？请在实验报告中说明。**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f0e73c09eb8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在我们可以将自动求导功能打开，为训练做好准备\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4.  训练神经网络\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　在这一部分中，我们将在数据集 MNIST 上训练构建好的神经网络。\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　在定义完神经网络之后，我们还需要在 torch.nn 包中选择合适的损失函数 (loss function) 来评估网络输出与理想值之间的差别。常用的损失函数都已经定义在了 torch.nn 中，比如均方误差 (nn.MSELoss)、多分类的交叉熵 (nn.CrossEntropyLoss) 及二分类的交叉熵 (nn.BCELoss)，等等。由于我们将进行手写字体0到9的识别，本次实验我们将选用交叉熵损失函数。\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　一个损失函数需要一对输入：模型的实际输出和目标输出。基于此，损失函数将计算一个值 (loss) 来评估实际输出距离目标输出有多远。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　除了损失函数以外，我们还需要一个能更直观的反映分类准确性的函数，方便我们了解训练的情况。请大家阅读并理解以下 get_num_correct 的代码每一步在做什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):  # get the number of correct times\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　在深度学习的训练过程中，我们需要通过不断调整参数使得损失最小化。优化算法就是一种调整模型参数更新的策略。在这里，我们需要用到一个新的包：torch.optim，其中“optim”是“optimizer”的缩写，它包含了多种常用的优化算法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　本次实验我们将使用随机梯度下降法 (SGD) 来对网络进行优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(network.parameters(), lr=0.1)  # lr: 学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　现在我们已经做好了训练的前期准备。在开始大规模的训练前，我们先来观察一个批次 (batch) 的图片是如何被训练的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　首先，我们取出一个 batch 的样本，传递给 network，并计算损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3154964447021484"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "images, labels = batch\n",
    "\n",
    "preds = network(images)\n",
    "loss = loss_func(preds, labels)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　现在我们有了 loss，下一步可以计算偏导 (gradients)。为了计算偏导，我们会在损失张量上调用反向函数 loss.backward()，PyTorch 会自动帮我们做相关的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　我们可以看看100张图片中分类正确的次数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_correct(preds, labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　下一步是使用这些偏导来更新网络的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()  # 更新参数的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　我们将同一批样本再次传递给更新后的神经网络，看看 loss 和分类正确的次数有什么变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  2.3077101707458496\n",
      "number of correct times:  10\n"
     ]
    }
   ],
   "source": [
    "preds = network(images)\n",
    "loss = loss_func(preds, labels)\n",
    "print(\"loss: \", loss.item())\n",
    "print(\"number of correct times: \", get_num_correct(preds, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　可以看到 loss 有些微的下降，说明我们确实是在朝着损失减小的方向调整参数。下面我们来完整实现整个训练过程。\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　**请大家补全以下代码，在实验报告中展示相关代码并做出说明，训练结果请截图保存。**    \n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 correct times: 53153 training accuracy: 88.588 % total_loss: 217.655\n",
      "epoch: 1 correct times: 58485 training accuracy: 97.475 % total_loss: 48.118\n",
      "epoch: 2 correct times: 58939 training accuracy: 98.232 % total_loss: 33.544\n",
      "epoch: 3 correct times: 59203 training accuracy: 98.672 % total_loss: 26.443\n",
      "epoch: 4 correct times: 59294 training accuracy: 98.823 % total_loss: 22.080\n",
      "epoch: 5 correct times: 59404 training accuracy: 99.007 % total_loss: 18.717\n",
      "epoch: 6 correct times: 59479 training accuracy: 99.132 % total_loss: 16.130\n",
      "epoch: 7 correct times: 59556 training accuracy: 99.260 % total_loss: 13.556\n",
      "epoch: 8 correct times: 59636 training accuracy: 99.393 % total_loss: 11.578\n",
      "epoch: 9 correct times: 59651 training accuracy: 99.418 % total_loss: 10.386\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 10\n",
    "\n",
    "for epoch in range(total_epochs):  # 训练周期\n",
    "\n",
    "    total_loss = 0\n",
    "    total_train_correct = 0\n",
    "\n",
    "    for batch in train_loader:  # get a batch from the dataloader\n",
    "        \n",
    "        \n",
    "        # 读取样本数据，完成正向传播，计算损失\n",
    "        \n",
    "        ##################### please finish the code ########################\n",
    "        \n",
    "        # images, labels = XXX        \n",
    "        # preds = XXX\n",
    "        # loss = XXX\n",
    "        images, labels = batch\n",
    "        preds = network(images)\n",
    "        loss = loss_func(preds, labels)\n",
    "        ################################ end ################################\n",
    "\n",
    "                \n",
    "        # 下面这行非常重要，它使得优化器 (optimizer) 将权重的偏导重新归零；\n",
    "        # 如果不归零，那么在反向传播时，计算出来的偏导会累加在原先的偏导上，\n",
    "        # 造成错误。\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        # 完成反向传播，更新参数\n",
    "        \n",
    "        ##################### please finish the code ########################\n",
    "        \n",
    "        # 反向传播 （一行代码）\n",
    "        loss.backward()\n",
    "        \n",
    "        # 更新参数 （一行代码）        \n",
    "        optimizer.step()\n",
    "\n",
    "        ################################ end ################################\n",
    "  \n",
    "        total_loss += loss.item()\n",
    "        total_train_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    print(\"epoch:\", epoch, \n",
    "          \"correct times:\", total_train_correct,\n",
    "          f\"training accuracy:\", \"%.3f\" %(total_train_correct/len(train_set)*100), \"%\", \n",
    "          \"total_loss:\", \"%.3f\" %total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_epochs = 10\n",
    "\n",
    "# for epoch in range(total_epochs):  # 训练周期\n",
    "#     total_loss = 0\n",
    "#     total_train_correct = 0\n",
    "\n",
    "#     for batch in train_loader:  # get a batch from the dataloader\n",
    "        \n",
    "#         # 读取样本数据，完成正向传播，计算损失,我们取出一个 batch 的样本，传递给 network，并计算损失。\n",
    "#         images, labels = batch\n",
    "#         preds = network(images)\n",
    "#         loss = loss_func(preds, labels)\n",
    "        \n",
    "#         # 将权重的偏导重新归零；如果不归零，那么在反向传播时，计算出来的偏导会累加在原先的偏导上，造成错误。\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # torch包中实现反向传播\n",
    "#         loss.backward()\n",
    "        \n",
    "#         # torch包中实现更新参数 \n",
    "#         optimizer.step()\n",
    "  \n",
    "#         total_loss += loss.item()\n",
    "#         total_train_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "#     print(\"epoch:\", epoch, \n",
    "#           \"correct times:\", total_train_correct,\n",
    "#           f\"training accuracy:\", \"%.3f\" %(total_train_correct/len(train_set)*100), \"%\", \n",
    "#           \"total_loss:\", \"%.3f\" %total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　训练结果看上去不错，让我们在测试集上看看准确率如何。\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　**请将测试结果保存，并展示在实验报告中。**    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct times: 9897 test accuracy: 98.970 % total_loss: 3.132\n"
     ]
    }
   ],
   "source": [
    "total_test_correct = 0\n",
    "total_loss = 0\n",
    "\n",
    "for batch in test_loader:  # get a batch from the dataloader\n",
    "    images, labels = batch\n",
    "    preds = network(images)\n",
    "    loss = loss_func(preds, labels)\n",
    "\n",
    "    total_loss += loss\n",
    "    total_test_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "print(\"correct times:\", total_test_correct, \n",
    "      f\"test accuracy:\", \"%.3f\" %(total_test_correct/len(test_set)*100), \"%\",\n",
    "      \"total_loss:\", \"%.3f\" %total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 5.  知识整合及应用：自定义神经网络在 Fashion-MNIST 上的训练与测试\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　至此，我们已经完整学习了如何基于 PyTorch 构建一个简单的卷积神经网络，并在数据集上训练和测试。为了加深大家对每一步的理解，之前我们将整个过程拆分开来细讲。在这一部分中，我们会把之前学的内容串起来，突出重点。\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　下面，请同学们将上述知识进行整合，自行设计一个7层神经网络（含三个卷积层和三个全连接层，卷积层可以尝试将 padding 设置为非零值），并在 Fashion-MNIST 数据集上进行训练和测试。\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　目标：测试集上准确率高于 87\\%。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>1) 　读取和处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size = 40\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root=\"./FashionMNIST\", train=True, download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root=\"./FashionMNIST\", train=False, download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=batch_size, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>2) 　自定义神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=2, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=96,  # 输入激活向量的长度\n",
    "                             out_features=120)  # 输出激活向量的长度\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # conv1\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)  # 这里我们用到了 nn.functional 包中的激活函数 relu\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)  # 这里我们用到了 nn.functional 包中的池化函数 max_pool2d （max pooling）\n",
    "\n",
    "        # conv2\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # conv3\n",
    "        t = F.relu(self.conv3(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # 展平\n",
    "        t = t.reshape((t.shape[0], -1))\n",
    "\n",
    "        # fc1\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # fc2\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # output layer\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n",
    "\n",
    "\n",
    "network = Network3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>3) 　损失函数和准确率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "def get_num_correct(preds, labels):  # get the number of correct times\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>4) 　优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(network.parameters(), lr=0.1)  # lr: 学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>5) 　训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 correct times: 36090 training accuracy: 60.150 % total_loss: 1571.385\n",
      "epoch: 1 correct times: 48363 training accuracy: 80.605 % total_loss: 765.990\n",
      "epoch: 2 correct times: 50343 training accuracy: 83.905 % total_loss: 645.171\n",
      "epoch: 3 correct times: 51275 training accuracy: 85.458 % total_loss: 581.637\n",
      "epoch: 4 correct times: 51809 training accuracy: 86.348 % total_loss: 543.634\n",
      "epoch: 5 correct times: 52193 training accuracy: 86.988 % total_loss: 514.942\n",
      "epoch: 6 correct times: 52622 training accuracy: 87.703 % total_loss: 490.967\n",
      "epoch: 7 correct times: 52754 training accuracy: 87.923 % total_loss: 477.049\n",
      "epoch: 8 correct times: 52946 training accuracy: 88.243 % total_loss: 464.435\n",
      "epoch: 9 correct times: 53183 training accuracy: 88.638 % total_loss: 450.689\n",
      "epoch: 10 correct times: 53276 training accuracy: 88.793 % total_loss: 441.395\n",
      "epoch: 11 correct times: 53410 training accuracy: 89.017 % total_loss: 431.796\n",
      "epoch: 12 correct times: 53531 training accuracy: 89.218 % total_loss: 422.226\n",
      "epoch: 13 correct times: 53597 training accuracy: 89.328 % total_loss: 417.833\n",
      "epoch: 14 correct times: 53676 training accuracy: 89.460 % total_loss: 408.210\n",
      "epoch: 15 correct times: 53802 training accuracy: 89.670 % total_loss: 401.369\n",
      "epoch: 16 correct times: 53907 training accuracy: 89.845 % total_loss: 398.102\n",
      "epoch: 17 correct times: 54051 training accuracy: 90.085 % total_loss: 390.215\n",
      "epoch: 18 correct times: 54078 training accuracy: 90.130 % total_loss: 384.694\n",
      "epoch: 19 correct times: 54152 training accuracy: 90.253 % total_loss: 378.117\n",
      "epoch: 20 correct times: 54307 training accuracy: 90.512 % total_loss: 372.815\n",
      "epoch: 21 correct times: 54334 training accuracy: 90.557 % total_loss: 367.131\n",
      "epoch: 22 correct times: 54357 training accuracy: 90.595 % total_loss: 368.400\n",
      "epoch: 23 correct times: 54395 training accuracy: 90.658 % total_loss: 365.040\n",
      "epoch: 24 correct times: 54503 training accuracy: 90.838 % total_loss: 357.515\n",
      "epoch: 25 correct times: 54485 training accuracy: 90.808 % total_loss: 355.890\n",
      "epoch: 26 correct times: 54545 training accuracy: 90.908 % total_loss: 351.904\n",
      "epoch: 27 correct times: 54614 training accuracy: 91.023 % total_loss: 351.285\n",
      "epoch: 28 correct times: 54601 training accuracy: 91.002 % total_loss: 348.248\n",
      "epoch: 29 correct times: 54669 training accuracy: 91.115 % total_loss: 344.277\n",
      "epoch: 30 correct times: 54665 training accuracy: 91.108 % total_loss: 343.476\n",
      "epoch: 31 correct times: 54799 training accuracy: 91.332 % total_loss: 340.803\n",
      "epoch: 32 correct times: 54789 training accuracy: 91.315 % total_loss: 337.837\n",
      "epoch: 33 correct times: 54816 training accuracy: 91.360 % total_loss: 331.282\n",
      "epoch: 34 correct times: 54827 training accuracy: 91.378 % total_loss: 334.642\n",
      "epoch: 35 correct times: 54988 training accuracy: 91.647 % total_loss: 328.223\n",
      "epoch: 36 correct times: 54888 training accuracy: 91.480 % total_loss: 331.879\n",
      "epoch: 37 correct times: 54938 training accuracy: 91.563 % total_loss: 328.842\n",
      "epoch: 38 correct times: 55042 training accuracy: 91.737 % total_loss: 321.158\n",
      "epoch: 39 correct times: 55045 training accuracy: 91.742 % total_loss: 321.690\n",
      "epoch: 40 correct times: 55011 training accuracy: 91.685 % total_loss: 322.163\n",
      "epoch: 41 correct times: 55115 training accuracy: 91.858 % total_loss: 316.945\n",
      "epoch: 42 correct times: 55075 training accuracy: 91.792 % total_loss: 322.309\n",
      "epoch: 43 correct times: 55075 training accuracy: 91.792 % total_loss: 320.097\n",
      "epoch: 44 correct times: 55124 training accuracy: 91.873 % total_loss: 318.142\n",
      "epoch: 45 correct times: 55199 training accuracy: 91.998 % total_loss: 312.684\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 100\n",
    "\n",
    "for epoch in range(total_epochs):  # 训练周期\n",
    "\n",
    "    total_loss = 0\n",
    "    total_train_correct = 0\n",
    "\n",
    "    for batch in train_loader:  # get a batch from the dataloader\n",
    "\n",
    "        # 读取样本数据，完成正向传播，计算损失\n",
    "\n",
    "        ##################### please finish the code ########################\n",
    "\n",
    "        # images, labels = XXX\n",
    "        # preds = XXX\n",
    "        # loss = XXX\n",
    "        images, labels = batch\n",
    "        preds = network(images)\n",
    "        loss = loss_func(preds, labels)\n",
    "        ################################ end ################################\n",
    "\n",
    "        # 下面这行非常重要，它使得优化器 (optimizer) 将权重的偏导重新归零；\n",
    "        # 如果不归零，那么在反向传播时，计算出来的偏导会累加在原先的偏导上，\n",
    "        # 造成错误。\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 完成反向传播，更新参数\n",
    "\n",
    "        ##################### please finish the code ########################\n",
    "\n",
    "        # 反向传播 （一行代码）\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新参数 （一行代码）\n",
    "        optimizer.step()\n",
    "\n",
    "        ################################ end ################################\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_train_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    print(\"epoch:\", epoch,\n",
    "          \"correct times:\", total_train_correct,\n",
    "          f\"training accuracy:\", \"%.3f\" % (total_train_correct / len(train_set) * 100), \"%\",\n",
    "          \"total_loss:\", \"%.3f\" % total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>6) 　测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_correct = 0\n",
    "total_loss = 0\n",
    "\n",
    "for batch in test_loader:  # get a batch from the dataloader\n",
    "    images, labels = batch\n",
    "    preds = network(images)\n",
    "    loss = loss_func(preds, labels)\n",
    "\n",
    "    total_loss += loss\n",
    "    total_test_correct += get_num_correct(preds, labels)\n",
    "\n",
    "print(\"correct times:\", total_test_correct,\n",
    "      f\"test accuracy:\", \"%.3f\" % (total_test_correct / len(test_set) * 100), \"%\",\n",
    "      \"total_loss:\", \"%.3f\" % total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 5.  实验报告\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>请同学们在实验报告中完成如下内容：\n",
    "    \n",
    "<font color=black size=3 face=雅黑>（关于代码：请大家将对应部分的代码和实验结果截图贴在实验报告中并进行相关说明即可，不要求上传完整的ipynb文件。如果大家在实验中进行了其他探索和尝试，也欢迎将其加在实验报告中。）\n",
    "\n",
    "<br>\n",
    "    \n",
    "<font color=black size=3 face=雅黑>- “0_pytorch_basics.ipynb”：5. Tensor 综合练习。（请完成代码，展示结果，并对代码和结果进行说明，回答相关问题。）\n",
    "    \n",
    "<font color=black size=3 face=雅黑>- “1_mnist_dataset_import.ipynb”：2. 读取并处理数据集 MNIST。（请完成对 train_set 相关代码的解释说明，并补全 test_set 的代码。）\n",
    "    \n",
    "<font color=black size=3 face=雅黑>- “2_python_cnn.ipynb”：3. 定义一个神经网络。（相关内容和要求已在文档中加粗。）\n",
    "    \n",
    "<font color=black size=3 face=雅黑>- “2_python_cnn.ipynb”：4. 训练神经网络。（相关内容和要求已在文档中加粗。）\n",
    "    \n",
    "    \n",
    "<font color=black size=3 face=雅黑>- “2_python_cnn.ipynb”：5. 知识整合及应用。（请完成代码，展示结果，并做出说明。）\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 20\n",
    "\n",
    "for epoch in range(total_epochs):  # 训练周期\n",
    "\n",
    "    total_loss = 0\n",
    "    total_train_correct = 0\n",
    "\n",
    "    for batch in train_loader:  # get a batch from the dataloader\n",
    "\n",
    "        # 读取样本数据，完成正向传播，计算损失\n",
    "        images, labels = batch\n",
    "        preds = network(images)\n",
    "        loss = loss_func(preds, labels)\n",
    "\n",
    "        # 将权重的偏导重新归零；如果不归零，那么在反向传播时，计算出来的偏导会累加在原先的偏导上，造成错误。\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播 \n",
    "        loss.backward()\n",
    "        # 更新参数 \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_train_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    print(\"epoch:\", epoch,\n",
    "          \"correct times:\", total_train_correct,\n",
    "          f\"training accuracy:\", \"%.3f\" % (total_train_correct / len(train_set) * 100), \"%\",\n",
    "          \"total_loss:\", \"%.3f\" % total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
