{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# PyTorch 基础 2 \n",
    "\n",
    "<br>\n",
    "\n",
    "## 0. 概述\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　在上一次实验中，我们围绕 PyTorch 的基本数据类型 Tensor 做过一系列练习。本次 PyTorch 基础练习，我们将学习如下要点：\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　　(1) 在 GPU 上实现模型训练与测试，并与 CPU 上的训练时长对比；\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　　(2) 进一步了解 PyTorch 的自动求导功能。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU vs. CPU\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　在这一部分，我们将学习如何将数据和模型从 CPU 转移到 GPU 上，并在 GPU 中进行训练与测试。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 数据集准备\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　我们首先来准备数据集 MNIST。如果数据集在原网上下载太慢，大家可以像上节课一样，自行从实验材料中下载四个压缩包，创建路径“./dataset_mnist/MNIST/raw”并将压缩包上传。\n",
    "\n",
    "<code>\n",
    "%%html\n",
    "<img src = \"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic4.zhimg.com%2Fv2-78abf1f3cfb557f9e4dd2fbb9c135ecc_b.jpg&refer=http%3A%2F%2Fpic4.zhimg.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1635427177&t=0617da4aedcf40fd21088e98c852a9de\", width = 45%>\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>与之前的实验相同，我们用 torchvision 读入数据，并对数据进行标准化处理，最后加载到 DataLoader 中。\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200  # 设置训练集和测试集的 batch size，即每批次将参与运算的样本数\n",
    "\n",
    "# 训练集\n",
    "train_set = torchvision.datasets.MNIST('./dataset_mnist', train=True, download=True,\n",
    "                                       transform=torchvision.transforms.Compose([\n",
    "                                           torchvision.transforms.ToTensor(),\n",
    "                                           torchvision.transforms.Normalize(\n",
    "                                               (0.1307,), (0.3081,)\n",
    "                                           )\n",
    "                                       ])\n",
    ")\n",
    "\n",
    "# 测试集\n",
    "test_set = torchvision.datasets.MNIST('./dataset_mnist', train=False, download=True,\n",
    "                                      transform=torchvision.transforms.Compose([\n",
    "                                          torchvision.transforms.ToTensor(),\n",
    "                                          torchvision.transforms.Normalize(\n",
    "                                              (0.1307,), (0.3081,)\n",
    "                                          )\n",
    "                                      ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 构建卷积神经网络\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>此处我们构建一个和上节课相同的卷积神经网络。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "        \n",
    "    def forward(self, t):\n",
    "        \n",
    "        # conv1\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t) \n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2) \n",
    "        \n",
    "        # conv2\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = t.reshape(batch_size, 12*4*4)\n",
    "        \n",
    "        # fc1\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # fc2\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # output layer\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3 在 GPU 上训练\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network1 = Network()\n",
    "network1.cuda()  # 将模型转移到 GPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()  # 损失函数：交叉熵损失\n",
    "optimizer1 = torch.optim.SGD(network1.parameters(), lr=0.1)  # 优化器\n",
    "\n",
    "def get_num_correct(preds, labels):  # 计算正确分类的次数\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 correct times: 47396 training accuracy: 78.993 % total_loss: 195.570\n",
      "epoch: 1 correct times: 57842 training accuracy: 96.403 % total_loss: 36.052\n",
      "epoch: 2 correct times: 58575 training accuracy: 97.625 % total_loss: 22.972\n",
      "epoch: 3 correct times: 58803 training accuracy: 98.005 % total_loss: 18.921\n",
      "epoch: 4 correct times: 59072 training accuracy: 98.453 % total_loss: 15.306\n",
      "epoch: 5 correct times: 59179 training accuracy: 98.632 % total_loss: 13.196\n",
      "epoch: 6 correct times: 59263 training accuracy: 98.772 % total_loss: 11.549\n",
      "epoch: 7 correct times: 59364 training accuracy: 98.940 % total_loss: 10.523\n",
      "epoch: 8 correct times: 59417 training accuracy: 99.028 % total_loss: 9.424\n",
      "epoch: 9 correct times: 59477 training accuracy: 99.128 % total_loss: 8.288\n",
      "epoch: 10 correct times: 59489 training accuracy: 99.148 % total_loss: 7.907\n",
      "epoch: 11 correct times: 59545 training accuracy: 99.242 % total_loss: 6.864\n",
      "epoch: 12 correct times: 59621 training accuracy: 99.368 % total_loss: 6.098\n",
      "epoch: 13 correct times: 59613 training accuracy: 99.355 % total_loss: 5.840\n",
      "epoch: 14 correct times: 59672 training accuracy: 99.453 % total_loss: 5.241\n",
      "epoch: 15 correct times: 59700 training accuracy: 99.500 % total_loss: 4.763\n",
      "epoch: 16 correct times: 59740 training accuracy: 99.567 % total_loss: 4.357\n",
      "epoch: 17 correct times: 59744 training accuracy: 99.573 % total_loss: 3.876\n",
      "epoch: 18 correct times: 59743 training accuracy: 99.572 % total_loss: 4.045\n",
      "epoch: 19 correct times: 59757 training accuracy: 99.595 % total_loss: 3.563\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 20\n",
    "time_start1 = time.time()\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_train_correct = 0\n",
    "\n",
    "    for batch in train_loader:  # 抓取一个 batch\n",
    "        \n",
    "        # 读取样本数据        \n",
    "        images, labels = batch\n",
    "        images = images.cuda()  # 数据转移到 GPU 上\n",
    "        labels = labels.cuda()  # 标签转移到 GPU 上\n",
    "        \n",
    "        # 完成正向传播，计算损失\n",
    "        preds = network1(images)\n",
    "        loss = loss_func(preds, labels)\n",
    "        \n",
    "        # 偏导归零\n",
    "        optimizer1.zero_grad()\n",
    "        \n",
    "        # 反向传播 \n",
    "        loss.backward()\n",
    "        \n",
    "        # 更新参数        \n",
    "        optimizer1.step()\n",
    "          \n",
    "        total_loss += loss.item()\n",
    "        total_train_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    print(\"epoch:\", epoch, \n",
    "          \"correct times:\", total_train_correct,\n",
    "          \"training accuracy:\", \"%.3f\" %(total_train_correct/len(train_set)*100), \"%\", \n",
    "          \"total_loss:\", \"%.3f\" %total_loss)\n",
    "    \n",
    "time_end1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>在 GPU 上的训练时长：\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time on GPU:  233.5057246685028\n"
     ]
    }
   ],
   "source": [
    "print(\"Training time on GPU: \", time_end1 - time_start1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.4 在 CPU 上训练，对比时长\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2 = Network()\n",
    "optimizer2 = torch.optim.SGD(network2.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 correct times: 47007 training accuracy: 78.345 % total_loss: 195.887\n",
      "epoch: 1 correct times: 57978 training accuracy: 96.630 % total_loss: 32.093\n",
      "epoch: 2 correct times: 58675 training accuracy: 97.792 % total_loss: 21.673\n",
      "epoch: 3 correct times: 58919 training accuracy: 98.198 % total_loss: 17.294\n",
      "epoch: 4 correct times: 59143 training accuracy: 98.572 % total_loss: 13.867\n",
      "epoch: 5 correct times: 59240 training accuracy: 98.733 % total_loss: 11.984\n",
      "epoch: 6 correct times: 59344 training accuracy: 98.907 % total_loss: 10.398\n",
      "epoch: 7 correct times: 59429 training accuracy: 99.048 % total_loss: 9.109\n",
      "epoch: 8 correct times: 59419 training accuracy: 99.032 % total_loss: 9.819\n",
      "epoch: 9 correct times: 59556 training accuracy: 99.260 % total_loss: 7.433\n",
      "epoch: 10 correct times: 59590 training accuracy: 99.317 % total_loss: 6.450\n",
      "epoch: 11 correct times: 59617 training accuracy: 99.362 % total_loss: 5.896\n",
      "epoch: 12 correct times: 59681 training accuracy: 99.468 % total_loss: 5.325\n",
      "epoch: 13 correct times: 59723 training accuracy: 99.538 % total_loss: 4.726\n",
      "epoch: 14 correct times: 59735 training accuracy: 99.558 % total_loss: 4.442\n",
      "epoch: 15 correct times: 59762 training accuracy: 99.603 % total_loss: 3.860\n",
      "epoch: 16 correct times: 59773 training accuracy: 99.622 % total_loss: 3.544\n",
      "epoch: 17 correct times: 59804 training accuracy: 99.673 % total_loss: 3.325\n",
      "epoch: 18 correct times: 59798 training accuracy: 99.663 % total_loss: 3.300\n",
      "epoch: 19 correct times: 59872 training accuracy: 99.787 % total_loss: 2.460\n"
     ]
    }
   ],
   "source": [
    "time_start2 = time.time()\n",
    "\n",
    "for epoch in range(total_epochs):  # 训练周期\n",
    "\n",
    "    total_loss = 0\n",
    "    total_train_correct = 0\n",
    "\n",
    "    for batch in train_loader:  # 抓取一个 batch\n",
    "        \n",
    "        # 读取样本数据        \n",
    "        images, labels = batch\n",
    "        \n",
    "        # 完成正向传播，计算损失\n",
    "        preds = network2(images)\n",
    "        loss = loss_func(preds, labels)\n",
    "        \n",
    "        # 偏导归零\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        # 反向传播 \n",
    "        loss.backward()\n",
    "        \n",
    "        # 更新参数        \n",
    "        optimizer2.step()\n",
    "          \n",
    "        total_loss += loss.item()\n",
    "        total_train_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    print(\"epoch:\", epoch, \n",
    "          \"correct times:\", total_train_correct,\n",
    "          f\"training accuracy:\", \"%.3f\" %(total_train_correct/len(train_set)*100), \"%\", \n",
    "          \"total_loss:\", \"%.3f\" %total_loss)\n",
    "    \n",
    "time_end2 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>在 CPU 上的训练时长：\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time on CPU:  764.838308095932\n"
     ]
    }
   ],
   "source": [
    "print(\"Training time on CPU: \", time_end2 - time_start2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　与 GPU 上的训练相比，训练时长有所增加。请注意，由于本例中神经网络较小，数据集也简单，所以使用 GPU 的加速效果不是特别显著，在复杂的任务中，GPU 将取得更好的加速效果。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>**请同学们在实验报告中对比模型在 CPU 和 GPU 上的训练时长。**\n",
    "   \n",
    "<br>\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch 与自动求导\n",
    "\n",
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　在上次实验中，我们已经知道 PyTorch 有自动求导功能，通过 \"loss.backward()\" 可以很方便的实现神经网络的反向传播。下面我们就来进一步了解这个功能。\n",
    "\n",
    "<code>\n",
    "%%html\n",
    "<img src = \"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic3.zhimg.com%2Fv2-58b9712696a499fd9b01380a9926a3b3_1200x500.jpg&refer=http%3A%2F%2Fpic3.zhimg.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1639062767&t=d95e4e63797c3b1a62afcab6c1fa2c0a\", width=45%>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black size=3 face=雅黑>　　Tensor 是 PyTorch 最基础的数据类型。上次实验中，我们介绍了 tensor 的三个基本属性: shape, dtype 和 device。今天我们将再介绍三个与自动求导相关的 tensor 属性，分别是 requires_grad, grad 和 grad_fn。\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　其中，requires_grad 用于说明当前张量是否需要在计算中保留对应的梯度信息（requires_grad=True 时保留）。对于那些要求梯度的 tensor，PyTorch 会存储他们相关的梯度信息和产生他们的操作。这将造成额外的内存消耗，因此为了优化内存使用，不做特殊说明时，创建一个 tensor 默认是不需要梯度的（即 requires_grad 默认为 False）。\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　grad 属性对应张量的偏导。在 requires_grad=False 的情况下，grad 不再改变，其值等于 None 或之前已经计算过的 grad。\n",
    "    \n",
    "<font color=black size=3 face=雅黑>　　grad_fn 属性记录了得到这个 tensor 进行的操作，例如加法、乘法运算等。\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1:  tensor([1., 2., 3.])\n",
      "t1.shape:  torch.Size([3])\n",
      "t1.dtype:  torch.float32\n",
      "t1.device:  cpu\n",
      "\n",
      "t1.requires_grad:  False\n",
      "t1.grad:  None\n",
      "t1.grad_fn:  None\n",
      "\n",
      "t2.requires_grad:  False\n",
      "t2.grad:  None\n",
      "t2.grad_fn:  None\n"
     ]
    }
   ],
   "source": [
    "# 创建 tensor t1\n",
    "t1 = torch.tensor([1,2,3], dtype=torch.float32)\n",
    "print(\"t1: \", t1)\n",
    "\n",
    "# 上次实验学习过的三种基本属性\n",
    "print(\"t1.shape: \", t1.shape)  # 形状\n",
    "print(\"t1.dtype: \", t1.dtype)  # 数据类型\n",
    "print(\"t1.device: \", t1.device)  # 默认为 cpu\n",
    "print(\"\")\n",
    "\n",
    "# 与自动求导相关的三种属性\n",
    "print(\"t1.requires_grad: \", t1.requires_grad)  # 用于说明当前张量是否需要在计算中保留对应的梯度信息（默认 False）    \n",
    "print(\"t1.grad: \", t1.grad)  # 偏导\n",
    "print(\"t1.grad_fn: \", t1.grad_fn)  # 得到这个 tensor 进行的操作\n",
    "print(\"\")\n",
    "\n",
    "# 基于 t1 计算得到张量 t2，其 requires_grad 属性默认与 t1 一致\n",
    "t2 = t1*2\n",
    "print(\"t2.requires_grad: \", t2.requires_grad)\n",
    "print(\"t2.grad: \", t2.grad)  \n",
    "print(\"t2.grad_fn: \", t2.grad_fn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1f77a35cbcd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 因为 t2.requires_grad=False，此时使用如下代码对 t2[0] 反向求导会报错\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# 因为 t2.requires_grad=False，此时使用如下代码对 t2[0] 反向求导会报错\n",
    "t2[0].backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>下面我们重新创建 t1，使其属性 requires_grad=True，观察以下代码的输出。\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1:  tensor([1., 2., 3.], requires_grad=True)\n",
      "t1.requires_grad:  True\n",
      "t1.grad:  None\n",
      "t1.grad_fn:  None\n",
      "\n",
      "t2.requires_grad:  True\n",
      "t2.grad:  None\n",
      "t2.grad_fn:  <MulBackward0 object at 0x7fa7801c2f28>\n"
     ]
    }
   ],
   "source": [
    "# 创建 tensor t1\n",
    "t1 = torch.tensor([1,2,3], dtype=torch.float32, requires_grad=True)\n",
    "print(\"t1: \", t1)\n",
    "\n",
    "# 查看与自动求导相关的三种属性\n",
    "print(\"t1.requires_grad: \", t1.requires_grad)  # 用于说明当前张量是否需要在计算中保留对应的梯度信息（默认 False）    \n",
    "print(\"t1.grad: \", t1.grad)  # 偏导\n",
    "print(\"t1.grad_fn: \", t1.grad_fn)  # 得到这个 tensor 进行的操作\n",
    "print(\"\")\n",
    "\n",
    "# 基于 t1 计算得到张量 t2，其 requires_grad 属性默认与 t1 一致\n",
    "t2 = t1*2\n",
    "print(\"t2.requires_grad: \", t2.requires_grad)\n",
    "print(\"t2.grad: \", t2.grad)  \n",
    "print(\"t2.grad_fn: \", t2.grad_fn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　可以看到 t2 的 requires_grad 也为 True，且 t2.grad_fn 中记录了得到 t2 进行的操作 (\"Mul\" 表示乘法)。下面我们来看看自动求导是如何做的。\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2[0].backward()  # 我们对 t2[0] 反向求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1.grad:  tensor([2., 0., 0.])\n",
      "t1.grad_fn:  None\n"
     ]
    }
   ],
   "source": [
    "print(\"t1.grad: \", t1.grad)\n",
    "print(\"t1.grad_fn: \", t1.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　可见 t1.grad 保存了 t2[0] 相对于 t1 的导数。（t2[0] 仅与 t1[0] 相关，因此导数为 [2,0,0]。）\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　下面我们再来看一个更接近实际情况的例子。发生在一个全连接层中**单个**神经元上的运算如下所示，其中 $a$ 表示输入激活值, $w$ 表示该神经元的权重，$b$ 表示偏置，$a$ 与 $w$ 皆是一维张量。该神经元上的线性计算结果 $z = a * w + b$，$z$ 是一个标量。\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1.,2.]], requires_grad=True)\n",
    "w = torch.tensor([[3.],[4.]], requires_grad=True)\n",
    "b = torch.tensor([6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.mm(a, w) + b\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.grad:  tensor([[3., 4.]])\n",
      "w.grad:  tensor([[1.],\n",
      "        [2.]])\n",
      "b.grad:  tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "\n",
    "print(\"a.grad: \", a.grad)\n",
    "print(\"w.grad: \", w.grad)\n",
    "print(\"b.grad: \", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>我们可以通过如下方法 (requires_grad_) 来随时修改一个 tensor 的 requires_grad 属性。\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1.,2.]], requires_grad=True)\n",
    "w = torch.tensor([[10.],[20.]], requires_grad=True)\n",
    "b = torch.tensor([6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a.requires_grad_(False)  # 将张量 a 的 requires_grad 属性重置为 False\n",
    "\n",
    "z = torch.mm(a, w) + b\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.grad:  None\n",
      "w.grad:  tensor([[1.],\n",
      "        [2.]])\n",
      "b.grad:  tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "\n",
    "print(\"a.grad: \", a.grad)  # None\n",
    "print(\"w.grad: \", w.grad)\n",
    "print(\"b.grad: \", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>在一个真实的神经网络中，我们可以很方便的查看每层参数的导数。首先，我们取出一个 batch 的样本，传递给 network，并计算损失。\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3110077381134033"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = Network()\n",
    "batch = next(iter(train_loader))\n",
    "images, labels = batch\n",
    "\n",
    "preds = network(images)\n",
    "loss = loss_func(preds, labels)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font color=black size=3 face=雅黑>　　现在我们有了 loss，下一步可以使用 loss.backward() 计算偏导，PyTorch 会自动帮我们做相关的计算。在调用 loss.backward() 前，我们先检查一下第一个卷积层 conv1。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network.conv1: \n",
      " Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) \n",
      "\n",
      "network.conv1.weight.data.shape: \n",
      " torch.Size([6, 1, 5, 5]) \n",
      "\n",
      "network.conv1.weight.data: \n",
      " tensor([[[[-0.0449, -0.0154,  0.1726,  0.1990,  0.0540],\n",
      "          [ 0.0357, -0.1352,  0.1075,  0.0187,  0.1720],\n",
      "          [-0.0247, -0.1631, -0.0904,  0.1197,  0.0477],\n",
      "          [ 0.1917,  0.1586, -0.0250, -0.1857, -0.0512],\n",
      "          [-0.1307, -0.1811, -0.0955,  0.1714, -0.0448]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1397,  0.0865,  0.1119,  0.0320,  0.0990],\n",
      "          [ 0.0637, -0.0431, -0.1158,  0.1260, -0.1406],\n",
      "          [-0.0442, -0.1311, -0.0283, -0.0788,  0.0498],\n",
      "          [ 0.1961, -0.0384, -0.1773,  0.1945, -0.0459],\n",
      "          [-0.0639, -0.1666,  0.1595,  0.1933, -0.0768]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0877, -0.1281, -0.1778, -0.1731, -0.0442],\n",
      "          [ 0.0920,  0.0139, -0.1226, -0.0697,  0.0855],\n",
      "          [-0.1184, -0.0533, -0.0984, -0.1494,  0.1653],\n",
      "          [ 0.1371, -0.1016, -0.0461, -0.1720,  0.1870],\n",
      "          [-0.1062,  0.1078,  0.1669, -0.0723, -0.1089]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0835, -0.1158,  0.0760, -0.0897,  0.0261],\n",
      "          [-0.0990,  0.1612,  0.0320,  0.1388, -0.0536],\n",
      "          [ 0.0065,  0.0070, -0.0722,  0.1629, -0.1800],\n",
      "          [-0.0607, -0.0333,  0.1525,  0.1081,  0.1561],\n",
      "          [-0.1185,  0.0460, -0.1074, -0.1970,  0.0280]]],\n",
      "\n",
      "\n",
      "        [[[-0.0092,  0.0015, -0.0851,  0.1494, -0.1805],\n",
      "          [ 0.0908, -0.0406, -0.0273, -0.0263, -0.0846],\n",
      "          [-0.1354,  0.1509, -0.1212, -0.0272,  0.1082],\n",
      "          [ 0.1602, -0.1362, -0.1927, -0.0766, -0.1498],\n",
      "          [ 0.0937,  0.1860,  0.1820,  0.1725,  0.0202]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0910, -0.1290, -0.0900,  0.1494, -0.1557],\n",
      "          [-0.1124, -0.0662,  0.0731, -0.0290,  0.1424],\n",
      "          [ 0.0358, -0.0173, -0.0349,  0.1057,  0.1474],\n",
      "          [-0.0764,  0.0052,  0.0127, -0.0637, -0.0586],\n",
      "          [-0.0454,  0.0502, -0.0832, -0.0758,  0.1739]]]]) \n",
      "\n",
      "network.conv1.weight.grad:  None\n"
     ]
    }
   ],
   "source": [
    "# 查看 conv1 信息\n",
    "print(\"network.conv1: \\n\", network.conv1, \"\\n\")\n",
    "\n",
    "# 查看 conv1 参数\n",
    "print(\"network.conv1.weight.data.shape: \\n\", network.conv1.weight.data.shape, \"\\n\")\n",
    "print(\"network.conv1.weight.data: \\n\", network.conv1.weight.data, \"\\n\")\n",
    "\n",
    "# 查看偏导用 network.conv1.weight.grad\n",
    "# 运行以下代码，会发现输出为 None，说明目前还没有梯度\n",
    "print(\"network.conv1.weight.grad: \", network.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在运行反向函数\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network.conv1.weight.grad.shape: \n",
      " torch.Size([6, 1, 5, 5]) \n",
      "\n",
      "network.conv1.weight.grad: \n",
      " tensor([[[[-2.8441e-03, -4.1445e-03, -2.8533e-03, -2.0798e-03,  9.2551e-06],\n",
      "          [-5.6289e-04, -2.2342e-03, -1.6740e-03, -1.1345e-03, -3.2309e-04],\n",
      "          [-7.9662e-04, -2.5382e-03, -2.1988e-03, -6.8201e-04, -1.0163e-03],\n",
      "          [-3.2804e-03, -3.7188e-03, -2.8743e-03, -2.1172e-03, -1.1748e-03],\n",
      "          [-3.5901e-03, -3.2050e-03, -1.6132e-03, -6.6099e-04, -9.6127e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4007e-03,  1.2730e-03,  4.0646e-04, -2.2383e-03, -2.8743e-03],\n",
      "          [ 4.0802e-03,  2.4020e-03, -2.0438e-04, -1.9596e-03, -1.5713e-03],\n",
      "          [ 4.3766e-03,  1.7513e-03, -9.4140e-04, -1.3440e-03, -2.4142e-05],\n",
      "          [ 3.9015e-03,  2.7723e-03, -5.7056e-04, -7.9472e-04,  2.7943e-04],\n",
      "          [ 2.6285e-03,  1.5545e-03, -7.4485e-04, -1.0408e-03,  2.2509e-04]]],\n",
      "\n",
      "\n",
      "        [[[-4.8325e-03, -1.6001e-03, -9.4157e-04, -8.1408e-04, -4.0624e-04],\n",
      "          [-3.2856e-03, -8.2046e-04, -4.8646e-04, -5.2063e-04,  1.1227e-03],\n",
      "          [-1.5751e-03, -2.6620e-05, -4.4420e-04, -6.6391e-04,  2.6654e-03],\n",
      "          [ 5.9542e-04,  1.6883e-03,  2.1256e-03,  2.6922e-03,  4.9376e-03],\n",
      "          [ 2.8286e-03,  4.6021e-03,  5.3204e-03,  5.7587e-03,  6.9214e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9567e-03,  3.3899e-03,  2.7683e-03,  1.4705e-03,  1.8096e-03],\n",
      "          [ 4.1418e-03,  4.1193e-03,  4.2056e-03,  2.3018e-03,  1.5205e-03],\n",
      "          [ 1.0572e-03,  2.4261e-03,  1.4466e-03,  1.6721e-04,  2.8463e-04],\n",
      "          [ 3.2077e-05,  7.6276e-05, -4.5683e-04,  5.2389e-04,  1.3159e-03],\n",
      "          [-7.4282e-04, -1.7097e-03, -1.1398e-03,  1.6210e-05, -3.7815e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6228e-03,  7.2578e-05, -2.0612e-03, -2.3950e-03, -2.0198e-03],\n",
      "          [ 7.9393e-04, -3.8013e-04, -1.1923e-03,  2.6758e-04, -5.6573e-04],\n",
      "          [ 2.7028e-05,  1.8837e-03,  2.7599e-03,  2.1766e-03, -1.0371e-03],\n",
      "          [ 1.4249e-03,  3.9561e-03,  4.4341e-03,  1.7803e-03, -1.9030e-03],\n",
      "          [ 6.1811e-05, -6.1115e-04, -1.0577e-03, -2.2949e-03, -3.5751e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.8599e-03, -1.3964e-03,  1.3705e-03,  6.1158e-03,  6.3771e-03],\n",
      "          [ 2.0897e-04,  2.2532e-04,  2.5818e-03,  6.6008e-03,  7.5075e-03],\n",
      "          [ 5.8058e-04,  7.6250e-04,  3.3653e-03,  6.5746e-03,  7.6486e-03],\n",
      "          [-1.7522e-03, -8.1217e-06,  3.4243e-03,  6.5314e-03,  6.9300e-03],\n",
      "          [-2.6620e-03, -7.1503e-04,  2.5482e-03,  6.0416e-03,  4.7295e-03]]]])\n"
     ]
    }
   ],
   "source": [
    "# 再来看一下，会发现偏导被计算出来了，它是一个四维张量，其维度与 conv1 的权重张量相同\n",
    "print(\"network.conv1.weight.grad.shape: \\n\", network.conv1.weight.grad.shape, \"\\n\")\n",
    "print(\"network.conv1.weight.grad: \\n\", network.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
